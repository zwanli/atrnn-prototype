{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import argparse\n",
    "import ntpath\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "from prettytable import PrettyTable\n",
    "import pandas as pd\n",
    "\n",
    "from preprocessing import is_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: ParserWarning: Both a converter and dtype were specified for column doc_id - only the converter will be used\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: ParserWarning: Both a converter and dtype were specified for column citeulike_id - only the converter will be used\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: ParserWarning: Both a converter and dtype were specified for column pages - only the converter will be used\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:21: ParserWarning: Both a converter and dtype were specified for column month - only the converter will be used\n"
     ]
    }
   ],
   "source": [
    "path = '/home/wanli/data/Extended_ctr/citeulike_t_extended/paper_info.csv'\n",
    "null_token = 'NaN'\n",
    "now = datetime.datetime.now()\n",
    "    \n",
    "clean_file_path = path +'.cleaned'\n",
    "\n",
    "\n",
    "labels = ['doc_id','citeulike_id', 'type', 'journal', 'booktitle', 'series', 'pages', 'year', 'month', 'address']\n",
    "labels_dtype = {'doc_id':np.int32 , 'citeulike_id':np.int32, 'type': str, 'journal': str, 'booktitle': str, 'series': str,\n",
    "                  'pages':np.int32, 'month': str, 'address': str}\n",
    "# Month converter\n",
    "months = ['apr','aug', 'dec' ,'feb', 'jan' ,'jul' ,'jun' ,'mar' ,'may', 'nov', 'oct', 'sep']\n",
    "month_convert_func = lambda x: x if x in months else null_token\n",
    "\n",
    "number_convert_func = lambda x: x if is_number(x) else -1\n",
    "\n",
    "\n",
    "convert_func= {'month': month_convert_func, 'pages': number_convert_func, 'doc_id': number_convert_func,\n",
    "               'citeulike_id': number_convert_func}\n",
    "df = pd.read_table(clean_file_path, delimiter='\\t', index_col = 'doc_id', usecols=labels,dtype=labels_dtype,\n",
    "                     converters=convert_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25976, 9)\nciteulike_id    21017\ntype               12\njournal          4109\nbooktitle        2641\nseries            430\npages             162\nyear               85\nmonth              13\naddress          1659\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "# count of unique values:\n",
    "print (df.apply(pd.Series.nunique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n----------------------------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df_dummy' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9a4ecced2d3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m# .reset_index(name=\"count\").query(\"count > 3\")[\"index\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'----------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_dummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdf_dummy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_dummy' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#Filter values with frequency less than min_freq\n",
    "def filter(df, tofilter_list, min_freq):\n",
    "    for col in tofilter_list:\n",
    "        to_keep =  df[col].value_counts().reset_index(name=\"count\").query(\"count > %d\" %min_freq)[\"index\"]\n",
    "        to_keep = to_keep.values.tolist()\n",
    "        df[col] = [x if x in to_keep else 'NaN' for x in df[col] ]\n",
    "    return df\n",
    "\n",
    "tofilter_list = ['journal','booktitle','address']\n",
    "df = filter(df,tofilter_list,2)\n",
    "\n",
    "# Convert catigorical feature into one-hot encoding\n",
    "def dummmy_df(df, todummy_list):\n",
    "    for x in todummy_list:\n",
    "        dummies = pd.get_dummies(df[x], prefix=x, dummy_na=True)\n",
    "        df = df.drop(x,1)\n",
    "        df = pd.concat([df,dummies], axis=1)\n",
    "    return df\n",
    "\n",
    "todummy_list = ['type', 'journal', 'booktitle', 'series', 'month', 'address']\n",
    "df = dummmy_df(df,todummy_list)\n",
    "# print(df_dummy.head(2))\n",
    "# print (df2)\n",
    "print('----------------------------')\n",
    "# print (df_dummy['journal'].value_counts())\n",
    "# .reset_index(name=\"count\").query(\"count > 3\")[\"index\"]\n",
    "print('----------------------------')\n",
    "print(df_dummy.shape)\n",
    "print (df_dummy.apply(pd.Series.nunique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25976, 1471)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21257, 1471)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "citeulike_id                                                                                                 21016\npages                                                                                                          162\nyear                                                                                                            85\ntype_article                                                                                                     2\ntype_book                                                                                                        2\ntype_electronic                                                                                                  2\ntype_inbook                                                                                                      2\ntype_incollection                                                                                                2\ntype_inproceedings                                                                                               2\ntype_manual                                                                                                      2\ntype_misc                                                                                                        2\ntype_phdthesis                                                                                                   2\ntype_proceedings                                                                                                 2\ntype_techreport                                                                                                  2\ntype_unpublished                                                                                                 2\ntype_nan                                                                                                         1\njournal_NaN                                                                                                      2\njournal_academic medicine : journal of the association of american medical colleges                              2\njournal_acm comput. surv.                                                                                        2\njournal_acm computing surveys                                                                                    2\njournal_acm trans. comput. syst.                                                                                 2\njournal_acm trans. comput.-hum. interact.                                                                        2\njournal_acm trans. database syst.                                                                                2\njournal_acm trans. graph.                                                                                        2\njournal_acm trans. inf. syst.                                                                                    2\njournal_acm trans. internet technol.                                                                             2\njournal_acm trans. multimedia comput. commun. appl.                                                              2\njournal_acm trans. web                                                                                           2\njournal_acm transactions on programming languages and systems                                                    2\njournal_acta psychologica                                                                                        2\n                                                                                                             ...  \naddress_hingham, ma, usa                                                                                         2\naddress_institute for operations research and the management sciences (informs), linthicum, maryland, usa        2\naddress_london                                                                                                   2\naddress_london, uk                                                                                               2\naddress_london, uk, uk                                                                                           2\naddress_los alamitos, ca, usa                                                                                    2\naddress_menlo park, ca, usa                                                                                      2\naddress_morristown, nj, usa                                                                                      2\naddress_new york                                                                                                 2\naddress_new york, ny                                                                                             2\naddress_new york, ny, usa                                                                                        2\naddress_newton, ma, usa                                                                                          2\naddress_norwell, ma, usa                                                                                         2\naddress_orlando, fl, usa                                                                                         2\naddress_oxford, uk                                                                                               2\naddress_oxford, uk, uk                                                                                           2\naddress_philadelphia, pa, usa                                                                                    2\naddress_piscataway, nj, usa                                                                                      2\naddress_san diego, ca, usa                                                                                       2\naddress_san diego, usa                                                                                           2\naddress_san francisco, ca, usa                                                                                   2\naddress_secaucus, nj, usa                                                                                        2\naddress_stroudsburg, pa, usa                                                                                     2\naddress_tarrytown, ny, usa                                                                                       2\naddress_thousand oaks, ca, usa                                                                                   2\naddress_totowa, nj                                                                                               2\naddress_upper saddle river, nj, usa                                                                              2\naddress_usa                                                                                                      2\naddress_washington, dc, usa                                                                                      2\naddress_nan                                                                                                      1\nLength: 1471, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_dummy.shape)\n",
    "df_dummy.dropna(inplace=True)\n",
    "print(df_dummy.shape)\n",
    "print (df_dummy.apply(pd.Series.nunique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# min-max normalization:\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# x = df.loc[:,todummy_list].values #returns a numpy array\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(x)\n",
    "# df.loc[:,todummy_list] = pandas.DataFrame(x_scaled)\n",
    "\n",
    "values = df.values\n",
    "imputer = preprocessing.Imputer()\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "# count the number of NaN values in each column\n",
    "print(np.isnan(transformed_values).sum())\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(transformed_values)\n",
    "transformed_df= pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25976, 1893)\n(25976, 1893)\n"
     ]
    }
   ],
   "source": [
    "print(transformed_df.shape)\n",
    "print(x_scaled.shape)\n",
    "# print(transformed_df.nunique())\n",
    "# print (transformed_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25976, 1893)\n(1893,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.491811938722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# training= np.random.randint(2, size=(x_scaled.shape[0],x_scaled.shape[1]+1))\n",
    "# training[:,:-1] = x_scaled\n",
    "\n",
    "y= np.random.randint(2, size=(x_scaled.shape[1]))\n",
    "# y= y.reshape((y.shape[0],1))\n",
    "print(x_scaled.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# evaluate an LDA model on the dataset using k-fold cross validation\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, np.transpose(np.matrix(x_scaled)), np.transpose(y), cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}