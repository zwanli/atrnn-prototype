{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import argparse\n",
    "import ntpath\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "from prettytable import PrettyTable\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "from preprocessing import is_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:49: ParserWarning: Both a converter and dtype were specified for column doc_id - only the converter will be used\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:49: ParserWarning: Both a converter and dtype were specified for column citeulike_id - only the converter will be used\n/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:49: ParserWarning: Both a converter and dtype were specified for column pages - only the converter will be used\n"
     ]
    }
   ],
   "source": [
    "path = '/home/wanli/data/Extended_ctr/citeulike_a_extended/paper_info.csv'\n",
    "path = '/home/wanli/data/Extended_ctr/citeulike_a_extended/papers_info_corrected_pages_years.csv'\n",
    "null_token = 'NaN'\n",
    "now = datetime.datetime.now()\n",
    "    \n",
    "clean_file_path = path +'.cleaned'\n",
    "\n",
    "\n",
    "# Month converter\n",
    "months = ['apr','aug', 'dec','feb', 'jan' ,'jul' ,'jun' ,'mar' ,'may', 'nov', 'oct', 'sep']\n",
    "month_convert_func = lambda x: x if x in months else null_token\n",
    "\n",
    "def number_convert_func (x):\n",
    "    if x == '-1':\n",
    "        return null_token\n",
    "    if is_number(x):\n",
    "        if x == 'NaN':\n",
    "            return null_token\n",
    "        x = float(x)\n",
    "        x = int(x)\n",
    "        return x\n",
    "    return null_token\n",
    "\n",
    "def year_convert_func (x):\n",
    "    if is_number(x):\n",
    "        if x == 'NaN':\n",
    "            return null_token\n",
    "        x = float(x)\n",
    "        x = int(x)\n",
    "        if x < 1000:\n",
    "            return null_token\n",
    "        return now.year - x\n",
    "    else:\n",
    "        return null_token\n",
    "\n",
    "labels = ['doc_id', 'citeulike_id', 'type', 'pages', 'year']\n",
    "labels_dtype = {'doc_id': np.int32, 'citeulike_id': np.int32, 'type': str, 'pages': np.int32}\n",
    "convert_func= {'pages': number_convert_func, 'doc_id': number_convert_func, 'year': year_convert_func,\n",
    "               'citeulike_id': number_convert_func}\n",
    "# labels = ['doc_id', 'citeulike_id', 'type', 'journal', 'booktitle', 'series', 'pages', 'year', 'month', 'address']\n",
    "# labels_dtype = {'doc_id': np.int32, 'citeulike_id': np.int32, 'type': str, 'journal': str, 'booktitle': str,\n",
    "#                 'series': str,\n",
    "#                 'pages': np.int32, 'month': str, 'address': str}\n",
    "# convert_func = {'month': month_convert_func, 'pages': number_convert_func, 'doc_id': number_convert_func,\n",
    "#                 'citeulike_id': number_convert_func}\n",
    "\n",
    "df = pd.read_table(clean_file_path, delimiter='\\t', index_col = 'doc_id', usecols=labels,dtype=labels_dtype,\n",
    "                     na_values='\\\\N',na_filter=False,\n",
    "                     converters=convert_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16981, 4)\nciteulike_id    16962\ntype               15\npages             129\nyear               85\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "# count of unique values:\n",
    "print (df.apply(pd.Series.nunique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16981, 4)\nciteulike_id    16962\ntype               15\npages             129\nyear               85\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Filter values with frequency less than min_freq\n",
    "def filter(df, tofilter_list, min_freq):\n",
    "    for col in tofilter_list:\n",
    "        to_keep =  df[col].value_counts().reset_index(name=\"count\").query(\"count > %d\" %min_freq)[\"index\"]\n",
    "        to_keep = to_keep.values.tolist()\n",
    "        df[col] = [x if x in to_keep else 'NaN' for x in df[col] ]\n",
    "    return df\n",
    "\n",
    "tofilter_list = []\n",
    "df = filter(df,tofilter_list,2)\n",
    "print(df.shape)\n",
    "print (df.apply(pd.Series.nunique))\n",
    "\n",
    "# \n",
    "# # Convert catigorical feature into one-hot encoding\n",
    "# def dummmy_df(df, todummy_list):\n",
    "#     for x in todummy_list:\n",
    "#         dummies = pd.get_dummies(df[x], prefix=x, dummy_na=True)\n",
    "#         df = df.drop(x,1)\n",
    "#         df = pd.concat([df,dummies], axis=1)\n",
    "#     return df\n",
    "\n",
    "# todummy_list = ['type']\n",
    "# df_dummy = dummmy_df(df,todummy_list)\n",
    "# # print(df_dummy.head(2))\n",
    "# # print (df2)\n",
    "# print('----------------------------')\n",
    "# # print (df_dummy['journal'].value_counts())\n",
    "# # .reset_index(name=\"count\").query(\"count > 3\")[\"index\"]\n",
    "# print('----------------------------')\n",
    "# print(df_dummy.shape)\n",
    "# print (df_dummy.apply(pd.Series.nunique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NaN' 4 5 8 7 12 2 3 28 10 17 9 42 203 14 11 6 20 19 18 16 56 13 29 41 39\n 15 40 22 31 25 23 59 27 48 33 35 34 51 30 60 43 32 24 83 1 21 70 37 46 62\n 53 45 26 36 38 47 44 50 74 57 49 573 -187 -191 -297 90 54 52 63 -64 55 97\n 65 77 -33 85 261 58 66 108 71 -194 75 68 88 93 73 117 92 78 64 152 61 133\n -398 -3 -51 5992 -2 3643 132 -23 87 -22 76 104 -437 -14 89 143 144 -155\n 1575 1836 103 72 -1 395 134 124 553 -140 -15 129 69 1694 -93 3808]\nNaN     5649\n5       1035\n7       1008\n9        946\n4        781\n3        773\n6        763\n11       666\n8        645\n10       546\n12       419\n13       360\n2        315\n14       310\n15       240\n1        227\n16       196\n17       180\n19       139\n18       138\n20       130\n21       119\n22       106\n24        88\n23        83\n25        70\n27        70\n29        69\n30        68\n26        64\n        ... \n-22        1\n-64        1\n-23        1\n-51        1\n1575       1\n63         1\n553        1\n395        1\n69         1\n71         1\n72         1\n73         1\n78         1\n83         1\n89         1\n103        1\n108        1\n117        1\n-1         1\n124        1\n129        1\n132        1\n133        1\n-3         1\n143        1\n144        1\n152        1\n203        1\n261        1\n134        1\nName: pages, Length: 129, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (df.pages.unique())\n",
    "print (df.pages.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NaN' 4 5 ..., 8 'NaN' 3]\n(array([-10,  -5,  -3,  -2,  -1,   1,   2,   3,   4,   5,   6,   7,   8,\n         9,  10,  11,  12,  13,  14,  15,  16,  17,  18,  19,  20,  21,\n        22,  23,  24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,\n        35,  36,  37,  38,  39,  40,  41,  42,  43,  44,  45,  46,  47,\n        48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,\n        61,  62,  63,  64,  65,  66,  68,  69,  70,  71,  72,  73,  74,\n        75,  76,  77,  78,  80]), array([  16, 5649,    1,    2,    1,  227,  315,  773,  781, 1035,  763,\n       1008,  645,  946,  546,  666,  419,  360,  310,  240,  196,  180,\n        138,  139,  130,  119,  106,   83,   88,   70,   64,   70,   53,\n         69,   68,   42,   39,   53,   49,   52,   37,   33,   21,   35,\n         21,   22,   19,   20,   12,   21,   17,   13,   15,   12,   13,\n         13,    7,   10,    6,    7,   10,    7,    4,    8,    9,    3,\n          4,    1,    3,    3,    3,    2,    1,    4,    1,    1,    1,\n          2,    2,    2,    2,    1,   42]))\n[-10.   -9.1  -8.2  -7.3  -6.4  -5.5  -4.6  -3.7  -2.8  -1.9  -1.   -0.1\n   0.8   1.7   2.6   3.5   4.4   5.3   6.2   7.1   8.    8.9   9.8  10.7\n  11.6  12.5  13.4  14.3  15.2  16.1  17.   17.9  18.8  19.7  20.6  21.5\n  22.4  23.3  24.2  25.1  26.   26.9  27.8  28.7  29.6  30.5  31.4  32.3\n  33.2  34.1  35.   35.9  36.8  37.7  38.6  39.5  40.4  41.3  42.2  43.1\n  44.   44.9  45.8  46.7  47.6  48.5  49.4  50.3  51.2  52.1  53.   53.9\n  54.8  55.7  56.6  57.5  58.4  59.3  60.2  61.1  62.   62.9  63.8  64.7\n  65.6  66.5  67.4  68.3  69.2  70.1  71.   71.9  72.8  73.7  74.6  75.5\n  76.4  77.3  78.2  79.1  80. ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSJJ6MTgkSb38f1MobI76qZ39AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8a2aab8630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pages = df.pages.values\n",
    "print(pages)\n",
    "pages=np.asarray(pages)\n",
    "\n",
    "\n",
    "pages[pages == 'NaN'] = -5\n",
    "pages=pages.astype(int)\n",
    "\n",
    "pages[pages < -10] = -10\n",
    "pages[pages > 80] = 80\n",
    "fig = plt.figure()\n",
    "n, bins, patches = plt.hist(pages,bins=100)\n",
    "print(np.unique(pages,return_counts=True))\n",
    "\n",
    "print(bins)\n",
    "# l = plt.plot(bins)\n",
    "# fig = pages.plot.hist(y=idx).get_figure()\n",
    "plt.title(\"Pages histogram\")\n",
    "plt.xlabel(\"Number of pages\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig('pages_hist.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NaN' '2004' '2002' '2001' '2000' '2003' '1998' '1999' '-1' '2005' '1993'\n '1994' '1962' '2006' '1997' '1996' '1992' '1986' '1988' '1995' '1991'\n '1985' '2007' '1990' '1989' '1987' '1976' '1978' '1982' '1950' '1961'\n '1979' '1972' '1974' '1973' '1981' '1970' '1965' '1968' '1975' '1983'\n '1984' '1980' '1971' '1957' '1960' '1948' '1977' '1912' '1929' '1952'\n '1969' '1956' '1967' '1949' '2009' '1946' '1936' '1966' '1964' '1941'\n '1958' '2013' '1959' '1935' '2014' '2015' '2010' '1953' '1963' '1943'\n '1951' '1871' '1947' '1954' '2011' '2008' '1944' '1955' '2016' '1899'\n '20060100' '1896' '3' '0' '1940' '1893' '2012']\n2007        1562\n2005        1542\n2008        1523\n2006        1505\n2009        1341\n2004        1315\n2003        1039\n2002         927\n2001         803\n2010         701\n2000         691\n-1           634\n1999         539\n1998         450\n1997         321\n1996         283\n1995         228\n1994         193\n1993         153\n1992         127\n1991         111\n1990         108\n1989          82\n1988          80\n1987          73\n1986          62\n1985          49\n1984          38\n1983          32\n1979          31\n            ... \n1950           4\n2013           3\n1966           3\n1946           3\n1949           3\n1953           3\n1959           2\n2016           2\n2014           2\n1936           2\n1958           2\n1948           2\n1947           2\n2012           2\n1943           2\n1940           1\n1935           1\n1896           1\n1955           1\n20060100       1\n1899           1\n1871           1\n1912           1\n3              1\n1944           1\n1951           1\n0              1\n1893           1\n1941           1\n1929           1\nName: year, Length: 88, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (df.year.unique())\n",
    "print (df.year.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1850.    1851.75  1853.5   1855.25  1857.    1858.75  1860.5   1862.25\n  1864.    1865.75  1867.5   1869.25  1871.    1872.75  1874.5   1876.25\n  1878.    1879.75  1881.5   1883.25  1885.    1886.75  1888.5   1890.25\n  1892.    1893.75  1895.5   1897.25  1899.    1900.75  1902.5   1904.25\n  1906.    1907.75  1909.5   1911.25  1913.    1914.75  1916.5   1918.25\n  1920.    1921.75  1923.5   1925.25  1927.    1928.75  1930.5   1932.25\n  1934.    1935.75  1937.5   1939.25  1941.    1942.75  1944.5   1946.25\n  1948.    1949.75  1951.5   1953.25  1955.    1956.75  1958.5   1960.25\n  1962.    1963.75  1965.5   1967.25  1969.    1970.75  1972.5   1974.25\n  1976.    1977.75  1979.5   1981.25  1983.    1984.75  1986.5   1988.25\n  1990.    1991.75  1993.5   1995.25  1997.    1998.75  2000.5   2002.25\n  2004.    2005.75  2007.5   2009.25  2011.    2012.75  2014.5   2016.25\n  2018.    2019.75  2021.5   2023.25  2025.  ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOMzMrBAXDjMzK8SFw8zMCnHhMDOzQv4bbxZkqkWAUuoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2888bd9ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year = df.year.values\n",
    "year=np.asarray(year)\n",
    "year[year == 'NaN'] = 2025\n",
    "# counts_nan = np.count_nonzero(np.isnan(year.astype(float)))\n",
    "# print(counts_nan)\n",
    "year=year.astype(int)\n",
    "year[year < 1850] = 1850\n",
    "year[(year > 2017) & (year != 2025)] = 2020\n",
    "fig = plt.figure()\n",
    "n, bins, patches = plt.hist(year,bins=100)\n",
    "print(bins)\n",
    "# l = plt.plot(bins)\n",
    "\n",
    "# fig = pages.plot.hist(y=idx).get_figure()\n",
    "plt.title(\"Years histogram\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig('year_hist.eps', format='eps', dpi=1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-10 '2004' '2002' ..., '2011' '2010' '2011']\n20\n"
     ]
    }
   ],
   "source": [
    "ye2 = df.year.values\n",
    "print(ye2)\n",
    "ye2=np.asarray(ye2)\n",
    "ye2[ye2 == 'NaN'] = -10\n",
    "print(len(ye2[ye2 == -10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article          12202\ninproceedings     2088\nbook              1490\nmisc               396\nelectronic         207\nproceedings        169\ntechreport         160\nincollection       124\ninbook              54\nunpublished         36\nphdthesis           25\nNaN                 20\nmastersthesis        7\nmanual               2\nbooklet              1\nName: type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (df.type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16981, 19)\n(16981, 19)\nciteulike_id          16962\npages                   263\nyear                     88\ntype_NaN                  2\ntype_article              2\ntype_book                 2\ntype_booklet              2\ntype_electronic           2\ntype_inbook               2\ntype_incollection         2\ntype_inproceedings        2\ntype_manual               2\ntype_mastersthesis        2\ntype_misc                 2\ntype_phdthesis            2\ntype_proceedings          2\ntype_techreport           2\ntype_unpublished          2\ntype_nan                  1\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_dummy.shape)\n",
    "df_dummy.dropna(inplace=True)\n",
    "print(df_dummy.shape)\n",
    "print (df_dummy.apply(pd.Series.nunique))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# min-max normalization:\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# x = df.loc[:,todummy_list].values #returns a numpy array\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# x_scaled = min_max_scaler.fit_transform(x)\n",
    "# df.loc[:,todummy_list] = pandas.DataFrame(x_scaled)\n",
    "\n",
    "values = df.values\n",
    "imputer = preprocessing.Imputer()\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "# count the number of NaN values in each column\n",
    "print(np.isnan(transformed_values).sum())\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(transformed_values)\n",
    "transformed_df= pd.DataFrame(x_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25976, 1893)\n(25976, 1893)\n"
     ]
    }
   ],
   "source": [
    "print(transformed_df.shape)\n",
    "print(x_scaled.shape)\n",
    "# print(transformed_df.nunique())\n",
    "# print (transformed_df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25976, 1893)\n(1893,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.491811938722\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# training= np.random.randint(2, size=(x_scaled.shape[0],x_scaled.shape[1]+1))\n",
    "# training[:,:-1] = x_scaled\n",
    "\n",
    "y= np.random.randint(2, size=(x_scaled.shape[1]))\n",
    "# y= y.reshape((y.shape[0],1))\n",
    "print(x_scaled.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# evaluate an LDA model on the dataset using k-fold cross validation\n",
    "model = LinearDiscriminantAnalysis()\n",
    "kfold = KFold(n_splits=3, random_state=7)\n",
    "result = cross_val_score(model, np.transpose(np.matrix(x_scaled)), np.transpose(y), cv=kfold, scoring='accuracy')\n",
    "print(result.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-01 22:49:37,599 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "from gensim import corpora\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-01 22:52:16,103 : INFO : loading projection weights from /home/wanli/data/word_embeddings.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-01 22:52:59,142 : INFO : loaded (302775, 200) matrix from /home/wanli/data/word_embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "fname ='/home/wanli/data/word_embeddings.txt'\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(fname, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.003150100318443387"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('information', 'system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sanchez', 0.5267158150672913),\n ('kelleher', 0.5113817453384399),\n ('wrath', 0.5070061683654785),\n ('yoatl', 0.47525104880332947),\n ('girl', 0.4729466438293457),\n ('tollu', 0.47179219126701355),\n ('lich', 0.4713619351387024),\n ('businessman', 0.47063136100769043),\n ('mansion', 0.47035470604896545),\n ('ruth', 0.4694134294986725)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman', 'king'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('program', 0.9820653200149536),\n ('compiler', 0.9291761517524719),\n ('instructions', 0.9030072689056396),\n ('binaries', 0.9001923203468323),\n ('c/c++', 0.8978627324104309),\n ('applet', 0.8968085050582886),\n ('firmware', 0.891533374786377),\n ('eprom', 0.8878062963485718),\n ('debugger', 0.8845652341842651),\n ('pc', 0.8814089894294739)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar_cosmul(positive=['computer', 'code'], negative=['biology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('recommendation', 0.8478092551231384),\n ('recommenders', 0.636306643486023),\n ('personalization', 0.596664309501648),\n ('tagir', 0.5812981724739075),\n ('question-answering', 0.5709900856018066),\n ('e-learning', 0.5520929098129272),\n ('collaborative-filtering', 0.5501213073730469),\n ('tagging', 0.5483794808387756),\n ('personalized', 0.546078085899353),\n ('cbir', 0.5428563952445984)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['recommender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-27.0\n"
     ]
    }
   ],
   "source": [
    "import  tensorflow as tf\n",
    "\n",
    "a = tf.placeholder(tf.float32, shape=[None,3], name=\"input_placeholder_a\")\n",
    "b = tf.placeholder(tf.float32, shape=[None,3], name=\"input_placeholder_b\")\n",
    "normalize_a = tf.nn.l2_normalize(a,0)        \n",
    "normalize_b = tf.nn.l2_normalize(b,0)\n",
    "cos_similarity = tf.losses.cosine_distance(a,b,dim=1)\n",
    "sess=tf.Session()\n",
    "cos_sim=sess.run(cos_similarity,feed_dict={a:[[1,2,3],[1,2,3]],b:[[2,4,6],[2,4,6]]})\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n[[ 0.26726124  0.53452247  0.80178368]\n [ 0.26726124  0.53452247  0.80178368]]\n[[ 0.26726124  0.53452247  0.80178368]\n [ 0.26726124  0.53452247  0.80178368]]\n"
     ]
    }
   ],
   "source": [
    "normalize_a = tf.nn.l2_normalize(a,1)        \n",
    "normalize_b = tf.nn.l2_normalize(b,1)\n",
    "x,y=sess.run([normalize_a, normalize_b],feed_dict={a:[[1,2,3],[2,4,6]],b:[[1,2,3],[2,4,6]]})\n",
    "print()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99999988]\n [ 0.99999988]]\n"
     ]
    }
   ],
   "source": [
    "cos_similarity = tf.losses.cosine_distance(normalize_a,normalize_b, reduction=tf.losses.Reduction.NONE,\n",
    "                                           dim=1)\n",
    "cos_sim=sess.run(cos_similarity,feed_dict={a:[[1,2,3],[2,4,6]],b:[[1,2,3],[2,4,6]]})\n",
    "print(1-cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19999999  0.19999999  0.19999999]\n [ 0.79999995  0.79999995  0.79999995]]\n[[ 0.40000004]\n [-1.39999986]]\n"
     ]
    }
   ],
   "source": [
    "radial_diffs = tf.multiply(normalize_a, normalize_b)\n",
    "print(sess.run(radial_diffs,feed_dict={a:[[1,2,3],[2,4,6]],b:[[1,2,3],[2,4,6]]}))\n",
    "losses = 1 - tf.reduce_sum(radial_diffs, axis=(1,), keep_dims=True)\n",
    "print(sess.run(losses,feed_dict={a:[[1,2,3],[2,4,6]],b:[[1,2,3],[2,4,6]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n[ 1.   1.   0.1]\n--------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.]\n [ 0.  1.]\n [ 0.  0.]]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Received a label value of -1 which is outside the valid range of [0, 1).  Label values: 1 1 -1\n\t [[Node: sparse_softmax_cross_entropy_loss_20/xentropy/xentropy = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_output2_44_0_1, _arg_labels2_44_0_0)]]\n\nCaused by op 'sparse_softmax_cross_entropy_loss_20/xentropy/xentropy', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-51-74ea13779171>\", line 50, in <module>\n    ce_spars= tf.losses.sparse_softmax_cross_entropy(logits=output, labels=labels,weights=weights\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py\", line 742, in sparse_softmax_cross_entropy\n    name=\"xentropy\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1693, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2491, in _sparse_softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Received a label value of -1 which is outside the valid range of [0, 1).  Label values: 1 1 -1\n\t [[Node: sparse_softmax_cross_entropy_loss_20/xentropy/xentropy = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_output2_44_0_1, _arg_labels2_44_0_0)]]\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1306\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Received a label value of -1 which is outside the valid range of [0, 1).  Label values: 1 1 -1\n\t [[Node: sparse_softmax_cross_entropy_loss_20/xentropy/xentropy = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_output2_44_0_1, _arg_labels2_44_0_0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-74ea13779171>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[0mfeed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0moutput5\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m ce_spars= tf.losses.sparse_softmax_cross_entropy(logits=output, labels=labels,weights=weights\n\u001b[1;32m---> 51\u001b[1;33m ).eval(feed)\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mce_spars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'--------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, feed_dict, session)\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m     \"\"\"\n\u001b[1;32m--> 541\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[1;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[0;32m   4083\u001b[0m                        \u001b[1;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4084\u001b[0m                        \"graph.\")\n\u001b[1;32m-> 4085\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4086\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4087\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1122\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1124\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1125\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1321\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Received a label value of -1 which is outside the valid range of [0, 1).  Label values: 1 1 -1\n\t [[Node: sparse_softmax_cross_entropy_loss_20/xentropy/xentropy = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_output2_44_0_1, _arg_labels2_44_0_0)]]\n\nCaused by op 'sparse_softmax_cross_entropy_loss_20/xentropy/xentropy', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2902, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3006, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3066, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-51-74ea13779171>\", line 50, in <module>\n    ce_spars= tf.losses.sparse_softmax_cross_entropy(logits=output, labels=labels,weights=weights\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py\", line 742, in sparse_softmax_cross_entropy\n    name=\"xentropy\")\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/nn_ops.py\", line 1693, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 2491, in _sparse_softmax_cross_entropy_with_logits\n    features=features, labels=labels, name=name)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Received a label value of -1 which is outside the valid range of [0, 1).  Label values: 1 1 -1\n\t [[Node: sparse_softmax_cross_entropy_loss_20/xentropy/xentropy = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_arg_output2_44_0_1, _arg_labels2_44_0_0)]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# a = tf.placeholder(tf.int32, shape =[None],name='labels')\n",
    "# b = tf.placeholder(tf.float32, shape = [None,1],name='logits')\n",
    "labels = tf.placeholder(tf.int32, shape =[None],name='labels2')\n",
    "output = tf.placeholder(tf.float32, shape =[None,None],name='output2')\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# feed_dict={b:np.array([[0.1],[0.8],[0.1],[0.5]]), a:np.array([0.9,0,0,0])}\n",
    "\n",
    "# c = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "#     logits=b, labels=a\n",
    "# ).eval(feed_dict)\n",
    "# print (c)\n",
    "# d = tf.losses.sparse_softmax_cross_entropy(labels=a,logits=b,reduction=tf.losses.Reduction.NONE).eval(feed_dict)\n",
    "# print(d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "output1=np.array([[0.3,0.3,0.4],[0.3 , 0.4  ,0.3 ],[0.1 , 0.2 , 0.7]])\n",
    "output2=np.array([[0.1,0.2,0.7],[0.1 , 0.7  ,0.2 ],[0.3 , 0.4 , 0.3]])\n",
    "output3=np.array([[0.2,0.4,1.4],[0.2 , 1.4  ,0.4 ],[0.6 , 0.8 , 0.6]])\n",
    "output4=np.array([[0.2,0.4],[0.2 , 1.4 ],[0.6 , 0.8 ]])\n",
    "output4=np.array([[0.2,0.8],[0.2 , 0.8 ],[0.6 , 0.4 ]])\n",
    "output5=np.array([[0.2],[0.8 ],[ 0.4 ]])\n",
    "\n",
    "\n",
    "\n",
    "label= np.array([1,1,-1])\n",
    "\n",
    "print('--------------------------')\n",
    "print(tf.maximum(tf.cast(label,tf.float32),0.1).eval())\n",
    "print('--------------------------')\n",
    "oh_label=tf.one_hot(labels,2)\n",
    "weights=[2,2,2]\n",
    "print(oh_label.eval({labels:label}))\n",
    "# feed = {labels:label,output: output5}\n",
    "# ce =tf.losses.softmax_cross_entropy(\n",
    "#     logits=output, onehot_labels=oh_label,weights=weights\n",
    "# ).eval(feed)\n",
    "# print(ce)\n",
    "# print(tf.reduce_mean(ce).eval())\n",
    "\n",
    "\n",
    "# label2= np.array([1,1,0])\n",
    "feed = {labels:label,output: output5}\n",
    "ce_spars= tf.losses.sparse_softmax_cross_entropy(logits=output, labels=labels,weights=weights\n",
    ").eval(feed)\n",
    "print(ce_spars)\n",
    "print('--------------------------')\n",
    "feed = {labels:label,output: output5}\n",
    "sm_output=tf.nn.softmax(output,dim=1)\n",
    "print(sm_output.eval(feed))\n",
    "\n",
    "# \n",
    "# ce_sm=-tf.reduce_sum(tf.cast(oh_label,tf.float32)* tf.log(sm_output), reduction_indices=[1]).eval(feed)\n",
    "# print(ce_sm)\n",
    "# print(tf.reduce_mean(ce_sm).eval())\n",
    "\n",
    "# cross_entropy = -tf.reduce_sum(label1 * tf.log(output3), reduction_indices=[1]).eval()\n",
    "# print(cross_entropy)\n",
    "# print(tf.reduce_mean(cross_entropy).eval())\n",
    "# prediction = tf.sigmoid(d).eval(feed_dict)\n",
    "# print(prediction)\n",
    "# predicted_class = tf.greater(prediction,0.5)\n",
    "# correct = tf.equal(predicted_class, tf.equal(a,1))\n",
    "# accuracy = tf.reduce_mean( tf.cast(correct, 'float') )\n",
    "# print(accuracy.eval(feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.69314718  0.59813881  1.03748798] [ 1.23983097  1.07291901  0.93983102]\n0.776258 1.08419\nlogits:\n [[ 0.5         0.5       ]\n [ 0.60000002  0.39999998]\n [ 0.80000001  0.2       ]]\nsoftmax logits:\n [[ 0.28943312  0.37797815]\n [ 0.31987306  0.34200874]\n [ 0.39069384  0.28001308]]\nsoftmax 2:\n [[ 0.5         0.5       ]\n [ 0.54983401  0.45016599]\n [ 0.64565629  0.35434368]]\nCross_entropy [ 0.69314718  0.79813892  0.43748799]\n[False False False]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from random import randint\n",
    "import numpy as np \n",
    "\n",
    "epsilon = 1e-8\n",
    "dims = [3,1]\n",
    "pos  = [1,0,1]\n",
    "tf.set_random_seed(42)\n",
    "# logits = tf.random_uniform(dims, maxval=1, dtype=tf.float32)\n",
    "logits = np.array([0.5, 0.6 ,0.8])\n",
    "# logits_2D = np.array([[ 0.94080913 , 0.05919087],\n",
    "#  [ 0.77504122 , 0.22495878],\n",
    "#  [ 0.74438941 , 0.25561059]])\n",
    "logits_2D = tf.stack([logits,tf.subtract(1.0,logits)],axis=1)+epsilon\n",
    "softmax_logits_2D = tf.nn.softmax(logits_2D,dim=0)\n",
    "ohe_labels = tf.one_hot(pos, 2)\n",
    "labels=tf.constant(pos)\n",
    "labels_2d=tf.stack([labels,tf.subtract(1,labels)], axis=1)\n",
    "# res1 = tf.nn.softmax_cross_entropy_with_logits(labels=ohe_labels,logits=logits_2D)\n",
    "\n",
    "# res2 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_2D, labels=classes)\n",
    "\n",
    "res3 = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_2D, labels=labels)\n",
    "\n",
    "res4 = -tf.reduce_sum(tf.to_float(labels_2d)*tf.log(softmax_logits_2D),reduction_indices=[1])\n",
    "\n",
    "# loss_fn =loss(logits_2D,labels_2d)\n",
    "with tf.name_scope('loss'):\n",
    "    logits = tf.reshape(logits_2D, (-1, 2))\n",
    "    shape = [logits.get_shape()[0], 2]\n",
    "    logits = logits + epsilon\n",
    "    labels = tf.to_float(tf.reshape(labels_2d, (-1, 2)))\n",
    "\n",
    "    softmax = tf.nn.softmax(logits)\n",
    "    cross_entropy = -tf.reduce_sum(labels * tf.log(softmax),\n",
    "                                   reduction_indices=[1])\n",
    "\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy,\n",
    "                                        name='xentropy_mean')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "    loss = tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "with tf.Session() as sess:\n",
    "    a,b,lab,logi,sm_log,softm,ce = sess.run([ res3,res4,labels,logits_2D,softmax_logits_2D,softmax,cross_entropy])\n",
    "    \n",
    "    print (a, b)\n",
    "    print(tf.reduce_mean(a).eval(),tf.reduce_mean(b).eval())\n",
    "    print('logits:\\n',logi)\n",
    "    print('softmax logits:\\n',sm_log)\n",
    "    print('softmax 2:\\n',softm)\n",
    "    print('Cross_entropy',ce)\n",
    "    # print('labels:\\n',lab)\n",
    "    # print('Loss\\n',loss_1)\n",
    "    \n",
    "    print (a == b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logits, labels):\n",
    "    \"\"\"Calculates the loss from the logits and the labels.\n",
    "\n",
    "    Args:\n",
    "      logits: Logits tensor, float - [batch_size, 2].\n",
    "      labels: Labels tensor, int32 - [batch_size, 2].\n",
    "\n",
    "    Returns:\n",
    "      loss: Loss tensor of type float.\n",
    "    \"\"\"\n",
    "    with tf.name_scope('loss'):\n",
    "        logits = tf.reshape(logits, (-1, 2))\n",
    "        shape = [logits.get_shape()[0], 2]\n",
    "        epsilon = tf.constant(value=1e-8, shape=shape)\n",
    "        logits = logits + epsilon\n",
    "        labels = tf.to_float(tf.reshape(labels, (-1, 2)))\n",
    "\n",
    "        softmax = tf.nn.softmax(logits)\n",
    "        cross_entropy = -tf.reduce_sum(labels * tf.log(softmax),\n",
    "                                       reduction_indices=[1])\n",
    "\n",
    "        cross_entropy_mean = tf.reduce_mean(cross_entropy,\n",
    "                                            name='xentropy_mean')\n",
    "        tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "        loss = tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1885.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1850.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988.0</td>\n",
       "      <td>234.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1885.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1850.0</td>\n",
       "      <td>160.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required modules\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "# Set charts to view inline\n",
    "%matplotlib inline\n",
    "# Create an example dataframe with a column of unnormalized data\n",
    "data = {'score': [234,24,14,27,np.nan,46,73,np.nan,59,160], \n",
    "        'b': [1988,1980,1999,2004,2014,np.nan,2016,np.nan,1885,1850]}#,'a': [1,0,1,0,1,1,0,1,0,1],}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f97a38ccb38>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD4CAYAAAAKA1qZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97a38d25f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# View the unnormalized data\n",
    "df.b.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986118</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.982152</td>\n",
       "      <td>0.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.991572</td>\n",
       "      <td>0.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994051</td>\n",
       "      <td>0.119149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.314894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.935052</td>\n",
       "      <td>0.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.917700</td>\n",
       "      <td>0.685106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986118</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.982152</td>\n",
       "      <td>0.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.991572</td>\n",
       "      <td>0.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994051</td>\n",
       "      <td>0.119149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.314894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.935052</td>\n",
       "      <td>0.255319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.917700</td>\n",
       "      <td>0.685106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f97a3979470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df.values.astype(float)\n",
    "# Create a minimum and maximum processor object\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "# Run the normalizer on the dataframe\n",
    "df_normalized = pd.DataFrame(x_scaled)\n",
    "\n",
    "df_normalized.plot(kind='bar')\n",
    "# View the dataframe\n",
    "df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.831325</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.897590</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.059091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.298295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.704819</td>\n",
       "      <td>0.145455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.704819</td>\n",
       "      <td>0.298295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.210843</td>\n",
       "      <td>0.204545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.831325</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.897590</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.927711</td>\n",
       "      <td>0.059091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.987952</td>\n",
       "      <td>0.298295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.704819</td>\n",
       "      <td>0.145455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.268182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.704819</td>\n",
       "      <td>0.298295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.210843</td>\n",
       "      <td>0.204545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.663636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = df.values\n",
    "imputer = preprocessing.Imputer()\n",
    "transformed_values = imputer.fit_transform(values)\n",
    "\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(transformed_values)\n",
    "transformed_df= pd.DataFrame(x_scaled)\n",
    "\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def dcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is discounted cumulative gain (dcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> dcg_at_k(r, 1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 1, method=1)\n",
    "    3.0\n",
    "    >>> dcg_at_k(r, 2)\n",
    "    5.0\n",
    "    >>> dcg_at_k(r, 2, method=1)\n",
    "    4.2618595071429155\n",
    "    >>> dcg_at_k(r, 10)\n",
    "    9.6051177391888114\n",
    "    >>> dcg_at_k(r, 11)\n",
    "    9.6051177391888114\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Discounted cumulative gain\n",
    "    \"\"\"\n",
    "    r = np.asfarray(r)[:k]\n",
    "    if r.size:\n",
    "        if method == 0:\n",
    "            return r[0] + np.sum(r[1:] / np.log2(np.arange(2, r.size + 1)))\n",
    "        elif method == 1:\n",
    "            return np.sum(r / np.log2(np.arange(2, r.size + 2)))\n",
    "        else:\n",
    "            raise ValueError('method must be 0 or 1.')\n",
    "    return 0.\n",
    "\n",
    "\n",
    "def ndcg_at_k(r, k, method=0):\n",
    "    \"\"\"Score is normalized discounted cumulative gain (ndcg)\n",
    "    Relevance is positive real values.  Can use binary\n",
    "    as the previous methods.\n",
    "    Example from\n",
    "    http://www.stanford.edu/class/cs276/handouts/EvaluationNew-handout-6-per.pdf\n",
    "    >>> r = [3, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "    >>> ndcg_at_k(r, 1)\n",
    "    1.0\n",
    "    >>> r = [2, 1, 2, 0]\n",
    "    >>> ndcg_at_k(r, 4)\n",
    "    0.9203032077642922\n",
    "    >>> ndcg_at_k(r, 4, method=1)\n",
    "    0.96519546960144276\n",
    "    >>> ndcg_at_k([0], 1)\n",
    "    0.0\n",
    "    >>> ndcg_at_k([1], 2)\n",
    "    1.0\n",
    "    Args:\n",
    "        r: Relevance scores (list or numpy) in rank order\n",
    "            (first element is the first item)\n",
    "        k: Number of results to consider\n",
    "        method: If 0 then weights are [1.0, 1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "                If 1 then weights are [1.0, 0.6309, 0.5, 0.4307, ...]\n",
    "    Returns:\n",
    "        Normalized discounted cumulative gain\n",
    "    \"\"\"\n",
    "    dcg_max = dcg_at_k(sorted(r, reverse=True), k, method)\n",
    "    print(dcg_max)\n",
    "    if not dcg_max:\n",
    "        return 0.\n",
    "    return dcg_at_k(r, k, method) / dcg_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.63092975357\n1.63092975357\n1.0\n1.0\n"
     ]
    }
   ],
   "source": [
    "r = [1, 2, 3, 0, 0, 1, 2, 2, 3, 0]\n",
    "r = [[1,1],[1,1],[1,0]]\n",
    "print(np.mean([ndcg_at_k(x,2,1) for x in r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1]*20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                                                  1\n0       17  4276 32443 37837 3378 7650 44590 42810 28819 4...\n1       48  40070 39891 9827 39406 45156 20392 18317 19332...\n2       66  35531 33478 46208 24430 13634 30698 31407 2230...\n3       54  2383 36288 43395 41495 9102 35490 1858 20309 2...\n4       30  30816 24430 40491 32766 20309 1223 30698 23613...\n5       36  14321 17329 20475 26937 17186 38235 38276 3069...\n6       21  5958 35646 37837 1535 29796 10457 20407 12347 ...\n7       28  7569 13421 28760 30180 23430 31867 39861 2120 ...\n8       39  40117 43055 36288 37682 24827 5851 33535 28329...\n9       12  28623 39682 29430 18187 44590 44986 38780 2300...\n10      37  7569 1934 28795 3687 20309 21006 19517 30698 2...\n11      32  11122 41063 3687 19229 44181 21006 10212 30698...\n12       7          12298 34605 37837 14977 41703 20629 30698\n13       6                37837 11423 20295 25507 30698 35133\n14       7             6403 6510 33816 28819 2120 45056 30698\n15      96  19766 31600 46208 41222 30698 14977 4057 4414 ...\n16      17  41589 5356 2061 38073 2595 29552 14977 17692 5...\n17      45  17782 23709 21329 31463 39491 18817 17692 3204...\n18       4                            39566 35531 27586 30698\n19      13  20919 31990 27586 2311 14977 20475 6281 302 31...\n20      28  34451 20016 20309 9818 30698 31876 31740 27200...\n21       4                            18700 11007 30698 45829\n22      67  16508 26347 24430 30266 2176 13244 31336 41651...\n23      47  35531 33712 33486 10612 31938 16212 21182 3687...\n24       0                                               None\n25      18  9046 33478 615 15326 42810 4020 19074 32555 11...\n26      33  12236 21046 14956 31683 34357 11423 41703 6861...\n27      69  39064 31548 45156 2176 13244 28989 22153 28912...\n28      72  14499 14300 24941 17817 31463 24430 27802 2047...\n29      26  2988 30858 4233 31866 12675 26852 35153 4637 3...\n...    ...                                                ...\n16950   29  13511 24080 27227 11851 30269 13657 45222 4602...\n16951   37  27546 23378 6300 46066 22211 16673 6861 2849 2...\n16952   42  21147 12711 11549 23279 40349 12277 35446 3802...\n16953   47  5996 14496 12276 43438 13796 13059 7736 17014 ...\n16954   36  41754 20571 1934 44286 20344 3688 21156 18544 ...\n16955    0                                               None\n16956   18  19021 10108 21046 6553 17427 2796 32668 18704 ...\n16957   29  41754 29430 20392 33509 3023 44286 28021 29466...\n16958   26  6552 709 12937 25875 13154 5948 23391 12054 24...\n16959  186  41754 41063 11513 38516 19377 8126 22700 2592 ...\n16960   16  44034 31876 16833 18372 39218 45014 21550 2260...\n16961   17  44034 31876 16833 21824 18372 36171 17508 2155...\n16962    0                                               None\n16963   49  16401 41120 38139 11513 40219 38250 13104 2270...\n16964   46  1934 1540 12530 8062 35947 38928 39237 40738 3...\n16965   19  31281 35272 1934 41703 33789 45653 11357 692 3...\n16966   19  14485 11065 18372 8015 3046 26128 43729 33581 ...\n16967   24  23098 35446 10657 1678 15718 40167 6861 9375 1...\n16968    0                                               None\n16969    0                                               None\n16970   22  15386 3687 29430 6398 31374 31876 40855 21523 ...\n16971   32  37868 16807 38063 589 44817 12932 44720 2768 1...\n16972   25  9415 17508 28407 35350 30698 26858 6935 37837 ...\n16973   28  38584 40644 4904 36827 40543 32468 7115 24545 ...\n16974   58  41754 9828 1934 16381 2651 8113 20344 18544 14...\n16975   25  38665 11821 6711 638 14845 29089 44590 13424 5...\n16976    0                                               None\n16977   39  16120 13421 11122 1858 4905 29261 12370 23480 ...\n16978   22  7196 1540 2651 13836 39200 20630 4414 24950 41...\n16979   58  16220 27218 18009 28117 30270 6711 21863 6858 ...\n\n[16980 rows x 2 columns]\n14607    357\n16045    325\n4179     269\n3981     253\n7545     217\n16959    186\n9103     173\n12244    168\n5120     159\n917      148\n9966     139\n15324    134\n226      132\n11328    126\n16896    125\n10944    124\n16386    117\n3440     112\n888      111\n11300    111\n10905    109\n16318    109\n11538    107\n477      107\n15815    106\n10605    103\n14988    102\n767      102\n9026     102\n7049     101\n        ... \n3222       0\n7661       0\n3243       0\n14712      0\n7684       0\n3235       0\n12731      0\n7688       0\n7690       0\n3230       0\n7694       0\n7695       0\n7697       0\n7698       0\n7703       0\n7727       0\n7706       0\n7709       0\n3214       0\n7712       0\n14735      0\n3210       0\n7713       0\n7714       0\n7715       0\n12725      0\n7717       0\n7718       0\n7720       0\n8489       0\nName: 0, Length: 16980, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path='/home/wanli/data/Extended_ctr/citeulike_a_extended/item-tag.dat'\n",
    "df = pd.read_csv(path, delimiter='|', names=['a'])\n",
    "df = df.a.str.split(' ', n=1, expand=True,)\n",
    "print(df)\n",
    "# df.sort_values(['0','1'], ascending=[True,True])\n",
    "print(df[0].astype(int).sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   3.   4.   5.   6.]\n [  7.   8.   9.  10.  11.  12.]] \n====\n [[[  1.   2.   3.   4.   5.   6.]\n  [  7.   8.   9.  10.  11.  12.]\n  [ 12.  12.  12.  12.  12.  12.]]\n\n [[ 12.  12.  12.  12.  12.  12.]\n  [ 12.  12.  12.  12.  12.  12.]\n  [ 12.  12.  12.  12.  12.  12.]]] \n====\n [[[  91.  217.]\n  [ 217.  559.]\n  [ 252.  684.]]\n\n [[ 252.  684.]\n  [ 252.  684.]\n  [ 252.  684.]]] [2 3 2]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "\n",
    "a = tf.constant(np.arange(1, 13, dtype=np.float32),\n",
    "                shape=[2, 6])\n",
    "b = tf.constant(np.arange(1, 13, dtype=np.float32),\n",
    "                shape=[2, 3,6])\n",
    "aa = tf.reshape(a,[tf.shape(a)[0],1,tf.shape(a)[1]])\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   3.   4.   5.   6.]\n [  7.   8.   9.  10.  11.  12.]] \n====\n [[[  1.   2.   3.   4.   5.   6.]\n  [  7.   8.   9.  10.  11.  12.]\n  [ 12.  12.  12.  12.  12.  12.]]\n\n [[ 12.  12.  12.  12.  12.  12.]\n  [ 12.  12.  12.  12.  12.  12.]\n  [ 12.  12.  12.  12.  12.  12.]]] \n====\n [[[  91.  217.]\n  [ 217.  559.]\n  [ 252.  684.]]\n\n [[ 252.  684.]\n  [ 252.  684.]\n  [ 252.  684.]]] [2 3 2]\n"
     ]
    }
   ],
   "source": [
    "c = tf.tensordot(b,a,axes=[[2],[1]])\n",
    "print(a.eval(),'\\n====\\n',b.eval(),'\\n====\\n',c.eval(), tf.shape(c).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91.0\n217.0\n252.0\n"
     ]
    }
   ],
   "source": [
    "print(np.dot([  1. ,  2.,   3. ,  4.  , 5.,   6.], [  1. ,  2.,   3. ,  4.  , 5.,   6.]))\n",
    "print(np.dot([  1. ,  2.,   3. ,  4.  , 5.,   6.], [  7. ,  8.,   9.  ,10.  ,11. , 12.]))\n",
    "print(np.dot([  1. ,  2.,   3. ,  4.  , 5.,   6.], [12.,  12.,  12.,  12.,  12.,  12.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "684.0\n"
     ]
    }
   ],
   "source": [
    "print(np.dot([   7.  , 8. ,  9. , 10.,  11. , 12.], [12.,  12.,  12.,  12.,  12.,  12.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1.   2.   3.   4.   5.   6.]]\n\n [[  7.   8.   9.  10.  11.  12.]]] \n====\n [[[  1.   2.   3.   4.   5.   6.]\n  [  7.   8.   9.  10.  11.  12.]\n  [ 12.  12.  12.  12.  12.  12.]]\n\n [[ 12.  12.  12.  12.  12.  12.]\n  [ 12.  12.  12.  12.  12.  12.]\n  [ 12.  12.  12.  12.  12.  12.]]] \n====\n [[  91.  217.  252.]\n [ 684.  684.  684.]] [2 3]\n"
     ]
    }
   ],
   "source": [
    "d = tf.einsum('aij,aj->ai',b, a)  # out[a,i,k] = sum_j s[a,i,j] * t[a, j, k])\n",
    "print(aa.eval(),'\\n====\\n',b.eval(),'\\n====\\n',d.eval(), tf.shape(d).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The default value of combiner will change from \"mean\" to \"sqrtn\" after 2016/11/01.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\nInstructions for updating:\nUse `tf.global_variables_initializer` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  9.  36.  81.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "example = tf.SparseTensor(indices=[[0], [1], [2]], values=[3, 6, 9], dense_shape=[3])\n",
    "\n",
    "vocabulary_size = 10\n",
    "embedding_size = 1\n",
    "var = np.array([0.0, 1.0, 4.0, 9.0, 16.0, 25.0, 36.0, 49.0, 64.0, 81.0])\n",
    "embeddings = tf.Variable(var)\n",
    "\n",
    "embed = tf.nn.embedding_lookup_sparse(embeddings, example, None)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    print(sess.run(embed)) # prints [  9.  36.  81.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(4, 1), dtype=int64)\n[[0]\n [1]\n [2]\n [3]]\n[0 2 0 1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "k = 6\n",
    "m = 4\n",
    "tags = 3, [[0,0],[1,1],[2,2],[2,0]]\n",
    "batch_size = 4\n",
    "idx = tf.constant(np.arange(batch_size, dtype=np.int64),\n",
    "                shape=[ batch_size,1])\n",
    "print(idx)\n",
    "v_idx = tf.constant([0,2,0,1])\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "print(idx.eval())\n",
    "print(v_idx.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensorValue(indices=array([[0, 0],\n       [0, 1],\n       [1, 3],\n       [2, 0],\n       [2, 1]]), values=array([ 1.,  1.,  1.,  1.,  1.], dtype=float32), dense_shape=array([ 5, 10]))\nWARNING:tensorflow:The default value of combiner will change from \"mean\" to \"sqrtn\" after 2016/11/01.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"SparseTensor_6/indices:0\", shape=(5, 2), dtype=int64), values=Tensor(\"ones_2:0\", shape=(5,), dtype=float32), dense_shape=Tensor(\"SparseTensor_6/dense_shape:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m       \u001b[0mstr_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 460\u001b[1;33m       \u001b[0mstr_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    461\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m     64\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[1;32m---> 65\u001b[1;33m                     (bytes_or_text,))\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fca58f04f28>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-29fb36f47447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtags_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_lookup_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtags_actual\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtags_actual\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup_sparse\u001b[1;34m(params, sp_ids, sp_weights, partition_strategy, name, combiner, max_norm)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     embeddings = embedding_lookup(\n\u001b[1;32m--> 411\u001b[1;33m         params, ids, partition_strategy=partition_strategy, max_norm=max_norm)\n\u001b[0m\u001b[0;32m    412\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_weights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    413\u001b[0m       \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36membedding_lookup\u001b[1;34m(params, ids, partition_strategy, name, validate_indices, max_norm)\u001b[0m\n\u001b[0;32m    292\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mmax_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m       transform_fn=None)\n\u001b[0m\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36m_embedding_lookup_and_transform\u001b[1;34m(params, ids, partition_strategy, name, max_norm, transform_fn)\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtransform_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_gather_and_clip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtransform_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/embedding_ops.py\u001b[0m in \u001b[0;36m_gather_and_clip\u001b[1;34m(params, ids, max_norm, name)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[0membs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0membs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0membs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(params, indices, validate_indices, name, axis)\u001b[0m\n\u001b[0;32m   2407\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2408\u001b[0m     return gen_array_ops.gather(params, indices,\n\u001b[1;32m-> 2409\u001b[1;33m                                 validate_indices=validate_indices, name=name)\n\u001b[0m\u001b[0;32m   2410\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2411\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mgather\u001b[1;34m(params, indices, validate_indices, name)\u001b[0m\n\u001b[0;32m   1217\u001b[0m   \"\"\"\n\u001b[0;32m   1218\u001b[0m   result = _op_def_lib.apply_op(\"Gather\", params=params, indices=indices,\n\u001b[1;32m-> 1219\u001b[1;33m                                 validate_indices=validate_indices, name=name)\n\u001b[0m\u001b[0;32m   1220\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    491\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m               raise TypeError(\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    488\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 490\u001b[1;33m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[0;32m    491\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m           \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    119\u001b[0m                                          as_ref=False):\n\u001b[0;32m    120\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[0mtensor_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m--> 102\u001b[1;33m       tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    103\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    462\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[0;32m    463\u001b[0m                       \u001b[1;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 464\u001b[1;33m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[0;32m    465\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Failed to convert object of type <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'> to Tensor. Contents: SparseTensor(indices=Tensor(\"SparseTensor_6/indices:0\", shape=(5, 2), dtype=int64), values=Tensor(\"ones_2:0\", shape=(5,), dtype=float32), dense_shape=Tensor(\"SparseTensor_6/dense_shape:0\", shape=(2,), dtype=int64)). Consider casting elements to a supported type."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "# tags_sparse = tf.SparseTensor(indices=tags[1], values=tf.ones(len(tags[1])), dense_shape=(m, tags[0]))\n",
    "tags_actual = tf.SparseTensor(idx,v_idx,dense_shape=[batch_size])\n",
    "# embedding_var = tf.get_variable(name=\"embedding\", shape=[tags[0], k])\n",
    "# embedding_var = tf.get_variable(name=\"embedding\", shape=[tags[0], k])\n",
    "# tags_matrix = tf.constant(np.random.randint(0,2,size=(5,10)),dtype=tf.float32)\n",
    "tags_matrix = tf.SparseTensor([[0,0],[0,1],[1,3],[2,0],[2,1]],values=tf.ones([5]),dense_shape=[5,10])\n",
    "\n",
    "print(tags_matrix.eval())\n",
    "tags_embeddings = tf.nn.embedding_lookup_sparse(tags_matrix, tags_actual,None)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "print(tags_actual.eval())\n",
    "# print(embedding_var.eval())\n",
    "print(sess.run(tags_embeddings)) # prints [  9.  36.  81.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.  1.]\n [ 2.  2.]\n [ 0.  1.]]\nSparseTensorValue(indices=array([[0, 0],\n       [0, 1],\n       [1, 0],\n       [2, 0],\n       [2, 1]]), values=array([ 1.,  1.,  1.,  1.,  1.], dtype=float32), dense_shape=array([3, 2]))\n[[ 1.  1.]\n [ 1.  0.]\n [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "tags_matrix = tf.SparseTensor([[0,0],[0,1],[1,0],[2,0],[2,1]],values=tf.ones([5]),dense_shape=[3,2])\n",
    "prediction = tf.constant(np.random.randint(0,3,size=(3,2)),dtype=tf.float32)\n",
    "print(prediction.eval())\n",
    "print(tags_matrix.eval())\n",
    "print(tf.sparse_tensor_to_dense(tags_matrix).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  4.  1.]\n [ 2.  2.  0.]\n [ 3.  4.  1.]]\n"
     ]
    }
   ],
   "source": [
    "logits = tf.sparse_tensor_dense_matmul(tags_matrix,tf.transpose(prediction))\n",
    "print(logits.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}